---
title: "Pipeline d'Indexation S√©mantique et Classification par IA pour l'ABES"
publishedAt: "2025-04-22"
summary: "Conception, d√©veloppement et validation d'un pipeline d'Intelligence Artificielle de bout en bout, visant l'indexation automatique du genre et de la forme des notices bibliographiques. Ce projet a n√©cessit√© l'optimisation des requ√™tes sur une base Oracle de plus de 10 milliards de lignes, l'utilisation d'embeddings s√©mantiques et le finetuning de mod√®les de Machine Learning (ML) et de Large Language Models (LLMs)."
images:
  - "/images/projects/ABESTF8/3.png"
team:
  - name: "Giovanni Gozzo"
    role: "D√©veloppeur IA (Alternance ABES)"
    avatar: "/images/team/Giovanni.png"
    linkedIn: "https://www.linkedin.com/in/giovanni-gozzo/"
---

# Pipeline d'Indexation Automatis√©e Bas√© sur l'Intelligence Artificielle

## 1. Contexte et Probl√©matique M√©tier √† l'ABES

Ce projet a √©t√© men√© au sein du laboratoire de l'**ABES (Agence bibliographique de l'enseignement sup√©rieur)**, organisme charg√© de la gestion du catalogue **Sudoc** (Syst√®me Universitaire de Documentation), qui centralise les collections des biblioth√®ques universitaires fran√ßaises.

Le d√©fi majeur pour les catalogueurs est l'attribution manuelle et chronophage des **descripteurs RAMEAU** (R√©pertoire d'Autorit√© Mati√®re Encyclop√©dique, Alphab√©tique et Unifi√©), notamment la classification par **genre ou forme** des ouvrages (exemples : "bandes dessin√©es", "romans", "th√®ses"). Une mauvaise indexation impacte directement la recherche documentaire par les utilisateurs finaux.

L'objectif de cette alternance √©tait de concevoir un **pipeline d'IA robuste** capable de :
1.  G√©rer l'extraction de donn√©es complexes √† partir d'une **base de donn√©es Oracle massive**.
2.  Appliquer des techniques de **Traitement Automatique du Langage Naturel (NLP)** pour d√©gager la s√©mantique.
3.  Proposer des **classifications automatiques** pour acc√©l√©rer le travail des experts.

## 2. Architecture du Pipeline d'Indexation (Conception Technique)

Le projet s'articule autour d'un pipeline en trois phases principales : l'extraction et le pr√©traitement, la vectorisation s√©mantique, et la classification par Machine Learning.

### 2.1. Extraction et Pr√©paration des Donn√©es Massives

La premi√®re √©tape, la plus critique, concerne la gestion de la base de donn√©es Oracle, contenant **plus de 10 milliards de lignes**.

* **Optimisation des Requ√™tes SQL** : Afin de surmonter les lenteurs inh√©rentes aux requ√™tes sur une telle volum√©trie, une m√©thode d'extraction par **segmentation des appels SQL** a √©t√© adopt√©e. Au lieu d'utiliser des `LEFT JOIN` co√ªteux et longs, le pipeline assemble les r√©sultats de plusieurs petites requ√™tes en m√©moire avec la librairie Pandas.
* **Nettoyage et Feature Engineering** :
    * **Normalisation** : Uniformisation des donn√©es textuelles.
    * **Lemmatisation** : Utilisation d'un `lemmatizer` pour r√©duire les mots √† leur racine (forme canonique), am√©liorant ainsi la qualit√© du jeu de donn√©es pour l'apprentissage.
    * **Enrichissement** : Traduction des codes bibliographiques bruts (tels que ceux de la zone 008) en libell√©s explicites, fournissant des *features* plus riches au mod√®le.

### 2.2. Vectorisation S√©mantique (Embeddings)

La conversion du texte trait√© en un format num√©rique exploitable par les algorithmes de Machine Learning est essentielle.

* **Limites des Approches Traditionnelles** : Les m√©thodes classiques comme Bag-of-Words ou TF-IDF ont √©t√© √©cart√©es pour leur incapacit√© √† capturer la **s√©mantique** et le **contexte** des descripteurs RAMEAU.
* **Adoption des Embeddings** : Le choix s'est port√© sur les **embeddings de phrases** (Sentence Embeddings) bas√©s sur des mod√®les *Transformer*. Les mod√®les **e5-large** et **e5-small** ont √©t√© privil√©gi√©s pour leur performance s√©mantique et leur capacit√© √† g√©n√©rer des repr√©sentations vectorielles de haute qualit√©.
* **Analyse en Composantes Principales (PCA/LDA)** : Pour visualiser la qualit√© des embeddings et confirmer la s√©parabilit√© des classes, des techniques de r√©duction de dimensionnalit√© telles que la **Linear Discriminant Analysis (LDA)** ont √©t√© appliqu√©es.

![2D](/images/projects/ABESTF8/3.png)
![3D](/images/projects/ABESTF8/4.png)


### 2.3. Classification par Mod√®les Supervis√©s

Plusieurs algorithmes ont √©t√© √©valu√©s pour d√©terminer la meilleure performance en classification multi-√©tiquette.

* **Comparaison des Mod√®les** : Les mod√®les test√©s incluent :
    * **Support Vector Classifier (SVC)**
    * **K-Nearest Neighbors (KNN)**
    * **Random Forest (RF)**
    * **R√©gression Logistique (LR)**
* **Choix Final** : La **R√©gression Logistique** a offert le meilleur compromis entre une haute performance, une vitesse d'entra√Ænement rapide et une faible consommation de ressources, rendant le pipeline industrialisable.
* **Hyperparam√®tres et Finetuning** : L'optimisation des hyperparam√®tres a √©t√© r√©alis√©e de mani√®re syst√©matique en utilisant la m√©thode **GridSearchCV** pour garantir une performance maximale du mod√®le s√©lectionn√©.


## 3. Exploration des Large Language Models (LLMs)

Parall√®lement aux mod√®les de Machine Learning classiques, une exploration a √©t√© men√©e sur les capacit√©s des Mod√®les de Langage (LLMs) pour la m√™me t√¢che.

* **Mod√®les Open Source Test√©s** : **Llama3** a √©t√© √©valu√© pour sa capacit√© √† contextualiser et √† pr√©dire les genres/formes.
* **Performances de Gemini** : Des tests avec **Gemini 2.0 Flash** ont d√©montr√© des r√©sultats tr√®s prometteurs en termes de pr√©cision, consolidant l'id√©e d'une **approche hybride** o√π l'IA traditionnelle (ML) pourrait √™tre enrichie ou remplac√©e par des LLMs sp√©cialis√©s.
* **Potentiel du RAG** : L'int√©gration future du **RAG (Retrieval-Augmented Generation)** est la perspective principale. En injectant le vocabulaire RAMEAU dans une base de donn√©es vectorielle, les LLMs pourraient √™tre personnalis√©s pour r√©f√©rencer uniquement les descripteurs officiels de l'ABES, am√©liorant drastiquement la pr√©cision contextuelle.

## 4. R√©sultats et Validation Scientifique

Le mod√®le final a √©t√© valid√© non seulement par des m√©triques informatiques, mais surtout par l'expertise des biblioth√©caires.

![humaine](/images/projects/ABESTF8/2.png)


### Performances du Mod√®le
Sur le jeu de donn√©es des 5 classes les plus fr√©quentes, le mod√®le de R√©gression Logistique a atteint des scores √©lev√©s :
* **Recall (Rappel) Moyen : 0,92**
* **Pr√©cision Moyenne : 0,85**

![Metrique](/images/projects/ABESTF8/1.png)

Ces r√©sultats confirment la capacit√© du pipeline √† identifier correctement la grande majorit√© des ouvrages, tout en maintenant une faible proportion de fausses classifications.

### Validation Humaine
La validation par les experts m√©tier a soulign√© un point essentiel : la notion de "bonne" classification est relative. Dans certains cas, le mod√®le a propos√© une classification non identique √† la classification initiale du Sudoc, mais consid√©r√©e comme **valide et acceptable** par le biblioth√©caire. Cette nuance justifie le r√¥le de l'outil comme une **aide √† la d√©cision** plut√¥t qu'un remplacement total de l'expertise humaine.


## 5. D√©fis, Enseignements et Perspectives

### D√©fis Techniques Relev√©s
1.  **Explosion de la Volum√©trie** : Ma√Ætriser l'interfa√ßage avec la base Oracle massive et concevoir des requ√™tes efficaces pour l'extraction de dizaines de millions de notices.
2.  **Ressources et Temps de Calcul** : R√©duire le temps d'ex√©cution li√© √† l'utilisation de mod√®les d'embeddings et de LLMs, n√©cessitant parfois l'acc√®s √† un serveur OVH avec acc√©l√©ration GPU.
3.  **Sp√©cificit√© du Vocabulaire RAMEAU** : Adapter les mod√®les de langage √† la complexit√© et √† la granularit√© du syst√®me de classification bibliographique fran√ßais.

### Comp√©tences Cl√©s D√©velopp√©es
* **Deep Learning & NLP** : Ma√Ætrise des embeddings, lemmatisation, et architecture des mod√®les de classification.
* **Optimisation Syst√®mes** : Expertise en optimisation SQL et en gestion des donn√©es distribu√©es.
* **Gestion de Projet** : Pilotage du projet en autonomie au sein du Labo, incluant des phases de recherche, d'exp√©rimentation et de validation.

### Perspectives Futures

Le projet laisse entrevoir de fortes perspectives d'√©volution pour l'ABES, notamment l'int√©gration du syst√®me dans le flux de travail quotidien pour all√©ger la charge des biblioth√©caires.

---

## üõ†Ô∏è Technologies Cl√©s du Projet

### üíª Langages & Frameworks
* **Python, Scikit-Learn, Pandas** : Langage principal de d√©veloppement, construction du mod√®le Machine Learning (ML), et manipulation/nettoyage des DataFrames pour g√©rer les donn√©es massives.

### ü§ñ NLP & Large Language Models (LLMs)
* **Hugging Face (Transformers), spaCy, LangChain** : Outils utilis√©s pour la g√©n√©ration des **embeddings s√©mantiques** (mod√®les e5-large/small), la **lemmatisation**, et l'interface d'exp√©rimentation avec les LLMs (Llama3, Gemini).

### üóÑÔ∏è Bases de Donn√©es & Gestion
* **Oracle (Base Sudoc), SQL, PL/SQL** : Base de donn√©es centrale de l'ABES, utilis√©e pour l'extraction optimis√©e des donn√©es du catalogue bibliographique massif.

### üß† Machine Learning & Algorithmes
* **R√©gression Logistique (LR), SVC, KNN, Random Forest** : Algorithmes de classification supervis√©e test√©s et compar√©s, avec la R√©gression Logistique fournissant les r√©sultats les plus prometteurs pour l'indexation multi-√©tiquette.

### üìä Optimisation & Visualisation
* **GridSearchCV, Hyperopt, Matplotlib, Seaborn, LDA/PCA** : Outils cruciaux pour le *finetuning* des hyperparam√®tres, et pour l'analyse et la **visualisation 3D/2D des clusters s√©mantiques** des embeddings.